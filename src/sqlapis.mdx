---
name: SQL APIs
route: /sqlapis
---

## Getting Started

A given SQL file defines a new API, automatically sets up [event queues](./events), generates Data Handlers templates, and [Generated Client Libraries](./clients). You just type SQL, EmbraceSQL does the rest.
This is a different approach than ORMs, which generate a meta schema, or mapping, which you then use in application code, which then generates SQL at runtime. This is a SQL first approach, and you are going to type a whole lot less to use it, as well as be able to access legacy databases.

The SQL you write is the SQL that is going to run.

As a simple example, let's make two new api endpoints in a directory by creating some sql files:

#### ./things/all.sql

```sql
SELECT * FROM things;
```

#### ./things/add.sql

```sql
INSERT INTO things(id, name) VALUES(:id, :name);
```

Notice the named parameters. In addition to positional parameters using `?`, you can set up named parameters using `:name` where `name` can be any continuous string you like. This format is as raw a sql as possible, with the specific idea that you can open and edit a SQL file using your favorite SQL editor or IDE to interactively test and build your query. EmbraceSQL doesn't dictate any particular developer tools.

If you open a browser to http://localhost:8765/ you will see EmbraceSQL has picked up your new files and there are now new APIs.

--todo--screenshot

Go ahead and give these APIs a test. This will give you a before and after look.

```shell
curl http://localhost:8765/things/all
curl --request POST --data '{"id": 100, "name": "cake"}' http://localhost:8765/things/add
curl http://localhost:8765/things/all
```

## Data Handlers

Data Handlers are an opportunity for you to add bits of code to handle events in the EmbraceSQL SQL API lifecycle. Data access can _almost always_ be pulled of with straight SQL, but sometimes you need a little adjustment.

Back in the local directory do `ls things` -- notice a few new files:

```
things/all.sql.before.js
things/all.sql.after.js
things/add.sql.before.js
things/add.sql.after.js
```

Take a look inside -- these are data handlers, generated in the default JavaScript (don’t worry multiple languages are supported, along with debugger attachment support!). `before` provides the ability to intercept a query on the way in, and `after` results on the way out.

You are really limited only by your imagination, but some suggestions for `before` handlers:

- Check security with code (more on our attribute based security model later)
- Re-write or replace parameter values
  And for `after` handlers:
- Remove or obfuscate secure data at the row/column level
- Make an additional query for more or associated data with EmbraceSQL

Data Handlers are hierarchical, to allow defaults. Starting from a like-named foo.sql, EmbraceSQL looks for `foo.sql.[event].[extension]` for a given event, across all extensions. From there, the local directory `[event].[extension]`, and repeatedly up each directoy to the root directory where EmbraceSQL is running.

OK -- so _resolution_, handlers run in order from root to child, so `./before.js` then `./things/before.js`, then `./things/all.before.js`. If at any point you throw an exception, this will make it all the way back to your calling client as an error message.

This means handlers are a chain:

root.before-->folder.before->query.before->query->query.after->folder.after->root.after

Let’s look inside the `add` handlers, and tweak some parameters.

#### things/add.sql.before.js

```javascript
export const before = (context) => {
  // modify a passed in parameter by name
  context.parameters.name = context.parameters.name + “-ahoy”;
}
```

#### things/add.sql.after.js

```javascript
export const after = (context) => {
  // run a query, no parameters
  context.results = context.databases.default.things.all.sql({});
};
```

And now -- give it a try, not only will you have a slightly different name than what you sent in -- you will get rows back as well, with one API call, instead of the two we previously ran.

```shell
curl --request POST --data '{"id": 200, "name": "ahoy"}' http://localhost:8765/things/add
```

The advantage here is you can batch up multiple interactions, even with multiple databases, behind a single trip over the network.

### Context

The Data Handler execution model relies on a context, which is shared between all handlers in a chain. This is the _one parameter_ passed to each handler, potentialy modified by a handler, and is available subsequent handlers.

EmbraceSQL itself creates this context when an SQL API call starts, and augments this context when running the SQL through to the database, adding the results from the database.

This shared context, and single parameter call signature for handlers makes handlers more consistent and affords easy access to object destructuring syntax features to pick out the bits of context you find interesting in your application.

### Using Multiple Databases

We've seen in [Databases](./databases) that you can have multiple databases -- so then -- how does an API -- an .sql file -- know which database to use? The answer is `default` is the default, but you can set the target database in a `before` handler. Let’s modify our handler to peek and see the database.

#### things/all.sql.before.js

```javascript
export const before = (context) => {
  console.log(context.database);
};
```

Back in the shell, give it a go.

```shell
curl http://localhost:8765/things/all
```

And the output:

```
{default: “sqlite:embracesql.db”}
```

You can set any SQL API to run on any database, or at least try to run. Just like we logged out the database earlier, we can set the database. Let’s take advantage of handler ordering and have every query in a new file use the `other` database.

#### other/before.js

```javascript
export const before = (context) => {
  context.database = context.databases.other;
  console.log(database);
};
```

That’s it, and using our handler resolution rules, every .sql in this folder on down will use the other database. So let’s create an SQL API endpoint.

#### other/strings.sql

```sql
SELECT * FROM strings;
```

And now call it and sure enough -- out comes hello world.

```shell
curl http://localhost:8765/other/strings
```

## SQL Dialect

EmbraceSQL does not define a new SQL dialect, it passes your SQL through directly to each database. This lets you use SQL fully, along with all the advanced features of your database, without the traditional limits created by ORM style query generators. It also lets you write SQL files with your existing favorite SQL editing tools.

The trade-off is of couse, you need to know the SQL of you database!

## Transactions

For any given database, you can begin, commit, or rollback a transaction at any time in any handler. You can do this in SQL, and you can do this in handler code.

Any transaction that was not committed by the time data is returned is automatically rolled back. Data can still return, which can let you do somewhat clever things like, insert data, read it back, and then an automatic roll back happen. This is a handy trick for database testing, where you can let transactions ‘undo’ the test data changes for you, restoring your database to a pristine state.

For example, let's modify a previous handler:

#### things/add.sql.before.js

```javascript
export const before = (context) => {
  // start a database transaction
  context.databases.default.transactions.begin();
  // modify a passed in parameter by name
  context.parameters.name = context.parameters.name + “-ahem”;
}
```

#### things/add.sql.after.js

```javascript
export const after = (context) => {
  // run a query, no parameters
  context.results = context.invoke.things.all.sql({});
  // do not commit, as this is commented out
  // note that by this time we have already done the insert
  // and queried the database
  // context.databases.default.transactions.commit();
  // we could also explicitly rollback, but this will happen on its own
  // context.databases.default.transactions.rollback();
};
```

And behold the rollback, which you can see in your shell.

```shell
curl http://localhost:8765/things/all
curl --request POST --data '{"id": 100, "name": "cough"}' http://localhost:8765/things/add
curl http://localhost:8765/things/all
```

This will show the table, then a modified table, then back to the original table.

## AutoCRUD

It's great to be able to have the full power of SQL when you need it -- but sometimes you just need to some basic CRUD. EmbraceSQL automatically inspects your databases and creates default APIs for your tables for working with single and multiple records operations by key.

Let's set up some tables for a really vanilla shopping cart, in our default testing SQLite database.

#### migrations/default/002.sql

```sql
CREATE TABLE orders(
  order_id INTEGER PRIMARY KEY AUTOINCREMENT,
  name TEXT NOT NULL
);
CREATE TABLE items(
  item_id INTEGER PRIMARY KEY AUTOINCREMENT,
  description TEXT NOT NULL
);
CREATE TABLE order_items(
  order_item_id INTEGER PRIMARY KEY AUTOINCREMENT,
  order_id INTEGER NOT NULL,
  item_id INTEGER NOT NULL,
  quantity INTEGER NOT NULL,
  FOREIGN KEY(order_id) REFERENCES orders(order_id),
  FOREIGN KEY(item_id) REFERENCES items(item_id)
);
```

```shell
docker run embrace-sql migrate
```

Without writing any SQL at all, you can 
* `POST` new rows to tables to Create
* `GET` table rows by key to Read
* `UPDATE` particular fields to values to Update
* `DELETE` by key to Delete

You can also make handlers for these automatically generated SQL APIs, without needing to write the SQL. The way to think about it is -- EmbraceSQL has a lot of SQL built in for the common cases, and you can write any SQL you like for more complex cases, all with the ability to have event handlers.

Even more powerful, with [Generated Client Libraries](./clients), you have typing and autocompletion available for you for every API. Let's see how AutoCRUD looks from TypeScript. So you can get a lot of data access without any SQL or mapping at all.

```typescript
import EmbraceSQL from "embrace-sql";

const client = new EmbraceSQL("http://localhost:8765");

// make some items we can order
const item_key = client.databases.default.items.create({description: "Paper"});
// and array valued
const more_item_keys = client.databases.items.create([
  {description: "Can"},
  {description: "Loaf"},
]);

// no need to pass in the key, it is an auto increment, but you 
// sure will need it to put in order items...
const order_key = client.databases.default.orders.create({name: "Sample"});

// now join items and orders with one of each
// again notice we don't need to mention the autoincrement
client.databases.default.order_items([item_key, ...more_item_keys].map( 
  (item_key) => ({order_key.order_id, item_key.item_id, quantity: 1})
);

// read back the master-detail graph
const my_order = client.databases.default.orders.read(order_key);
// notice three tables are joined automatically and you can get the description
console.log(my_order.name, my_order.order_items, my_order.order_items[0].description);

// hmm -- I really want two of that...
client.databases.default.order_items.update({...my_order.order_items, quantity: 2});

// nope -- I don't want it at all
client.database.default.orders.delete(order_key);

// but the items aren't deleted -- they are lookup data!
console.log(client.database.default.items.all());
```

Having an API is great, now let's add [Security](./security).
