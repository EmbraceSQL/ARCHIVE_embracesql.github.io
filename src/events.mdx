---
name: Events
route: /events
---

## Getting Started

One of the big choices in system design is CRUD or some form of EventSourcing / CQRS setup. EmbraceSQL -- embraces SQL -- C’s are UPDATE/INSERT/DELETE and Q’s are SELECT. They are separated by SQL itself. So CQRS is ‘free’.

Now for the event sourcing part. By default every SQL API generates an event internal to EmbraceSQL event processing queues. Commands - INSERT/UPDATE/DELETE -- can be twinned to a Kafka topic. The entire HTTP request, encoded as JSON is placed in the topic.

#### embracesql.yml

```yaml
twin_commands_to: kafka:hostname:port/topic
```


There is actually a bit more than that -- EmbraceSQL internally runs off queues, when you call an API, the inputs are enqueued, and run through a queue for each handler, as well as for the database query itself. EmbraceSQL is itself a SQL EventSourcing system -- where the events *are* the SQL queries, and the handlers are handling events.

## Data Events

### SQL API

This is the initial event in a series of events to proces a single SQL API call. This event is generated from inbound HTTP traffic, encoded as a single event object in memory, rendered as JSON, and published as a twin if so configured.

APIs are implemented as paired queues, request and response, with a correlation identifier. Calling clients over HTTP wait for a corresponding response message or a timeout.

### `before`

Each of the folder hierarchy based `before` handlers has a service queue, automatically defined, so that each folder, and each sql file has a before handling queue. Messages are placed in the root folder before handler, handled, and then passed down the folder hierarchy until a query is reached.

After the `before` handlers are processed, the resulting `context` is presented to a pool of SQL processing queues for each attached database. This allows concurrent data access without resorting to multithreading or traditional connection pooling.

When a query completes, the resulting data is attached to the context and passed back up the chain as `after` events.

### `after`

Each folder in the hierarchy, and the sql file itself has an automatically defined `after` event queue, which run in the reverse order as `before` events, from the sql file back to the root directory. Each handler runs, and passed up to the subsequent queue.

## System Events

While data events fire in response to SQL API calls, system events can fire at any time. 

### `token`

OpenID Connect authorization tokens are decoded and validated by default. But you can provide your own event handler that does your own token validation.

### `exception`

Exceptions raised in any handler on any queue are events on a single system wide exception queue, which can have its own handler. This gives you an ability to hook in to exceptions globally as needed for logging or telemetry.

### `resolve`

SQL API calls and AutoCRUD calls resovle to chain of event handlers and associated SQL. The `resolve` event lets you tap into this and replace any handler or SQL you like, running *before* the first `before` handler.

### `send`

As a message is just about to be sent to an external message stream, you have a chance to intercept it.

### `before-migration`

### `after-migration`

### `before-request`

### `after-request`

### `before-database-connection`

### `after-database-connection`

## Publshing Semantic Events

In your application, there will be actions and states that really mean something in the context of your application. Often you will want to publish an event when these happen, along with a contextual set of data. EmbraceSQL makes this eay by letting you simply publish any object, at any time, from any handler. 
The simple use case is to publish your context.